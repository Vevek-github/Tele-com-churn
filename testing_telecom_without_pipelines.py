# -*- coding: utf-8 -*-
"""testing_telecom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PAIot8WEwGDjq3lkSOhcGE1-fgDQE8f6
"""

#pip install -U scikit-learn==1.2.2

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#to ignore warnings
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.tree import plot_tree
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import TargetEncoder
import joblib

pd.set_option('display.max_columns',None)
dff = pd.read_csv(r"source_data.csv")
feature_to_scale =['account.length','voice.messages',  'intl.calls',
       'intl.charge', 'day.calls', 'day.charge', 'eve.calls', 'eve.charge',
       'night.calls', 'night.charge', 'customer.calls']
SS= StandardScaler()
dff[feature_to_scale]= SS.fit(dff[feature_to_scale])

"""# Load the models"""



"""# creating test_df   JUST USE "Sample_size:"
"""


def input_run(df:pd.DataFrame):
  best_gb = joblib.load(r"Models\best_gb")
  SS1 = joblib.load(r"Encoders\SS1")
  target_encoder = joblib.load(r"Encoders\target_enc")
  one_hot_enc= joblib.load(r"Encoders\one_hot_enc")
  
  
  sample_size = len(df)
  
  df.index = [x for x in range(sample_size)]

  """#Data Pre-Process"""
  
  df[['state']]= target_encoder.transform(df[['state']])                          # target encoding

  if df['day.charge'].dtype!=np.number :
    df['day.charge']=df['day.charge'].astype('float')
  if df['eve.mins'].dtype!=np.number :
    df['eve.mins']=df['eve.mins'].astype('float')

  df[['area.code.1','area.code.2']] =one_hot_enc.transform(df[['area.code']])     # One-hot-encoding
  
  columns_to_drop = ["eve.mins",   "day.mins",  "night.mins",  "intl.mins",'Unnamed: 0','voice.plan','churn','area.code']
  for i in columns_to_drop:
    if i in df.columns:
      df.drop(i, axis=1,inplace= True)                         # Dropping state varible
  
  df=df.dropna()                                               # drop null values
  num_cols = df.select_dtypes(include = np.number).columns
  cat_cols = df.select_dtypes(include ='object').columns
  
  df["intl.plan"] = df["intl.plan"].map({"no": 0, "yes": 1})   # Binary encoding
  df["intl.plan"] = df["intl.plan"].astype("int64")

  
  df[feature_to_scale]= SS.transform(df[feature_to_scale])   # Simple Standard scaling

  """# Loading best_gb model"""

  feature_names  =  ['state', 'account.length', 'voice.messages', 'intl.plan', 'intl.calls',
       'intl.charge', 'day.calls', 'day.charge', 'eve.calls', 'eve.charge',
       'night.calls', 'night.charge', 'customer.calls', 'area.code.1',
       'area.code.2']
  #print(df.head())
  df = df[feature_names]                     # Re- ordered features order to work in the model

  """# Output"""

  return best_gb.predict(df)


